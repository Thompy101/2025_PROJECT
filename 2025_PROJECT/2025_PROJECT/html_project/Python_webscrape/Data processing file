import os
import pandas as pd

# --- Configuration ---
# Path to the single merged CSV file created by the web scraper
# This should match the output location of your 'bso_scraper_verify_false' script
INPUT_CSV_FILE_PATH = r"C:\Users\Andrew\OneDrive\Documents\2025_PROJECT\2025_PROJECT\html_project\Python_webscrape\Webscrape Data\merged_bso_dispensing_data.csv"

# Define the output folder path for the processed files.
# IMPORTANT: Replace this with your desired output path if different.
OUTPUT_BASE_FOLDER = r"C:\Users\Andrew\OneDrive\Documents\2025_PROJECT\2025_PROJECT\Output Data" # Example path, please adjust

# --- User Input ---
try:
    # y_input is used for the output filename, can be 'ALL' or a specific year like '2024'
    y_input = input("Enter a reference for the output filename (e.g., 'ALL_Data' or '2024_Data'): ")
    str_chemist_input = input("Enter the Chemist number you want to filter by: ")
    chemist_filter_number = int(str_chemist_input)
except ValueError:
    print("Invalid input. Please enter a valid number for the Chemist filter.")
    exit() # Exit if input is invalid
except Exception as e:
    print(f"An unexpected error occurred during input: {e}")
    exit()

# Ensure the output folder exists
if not os.path.exists(OUTPUT_BASE_FOLDER):
    try:
        os.makedirs(OUTPUT_BASE_FOLDER)
        print(f"Created output directory: {OUTPUT_BASE_FOLDER}")
    except OSError as e:
        print(f"Error creating output directory {OUTPUT_BASE_FOLDER}: {e}")
        exit()

# --- Data Loading Function (Modified for a single CSV) ---
def load_single_csv_file(file_path):
    """
    Reads a single CSV file into a pandas DataFrame.
    """
    print(f"Loading data from: {file_path}")
    if not os.path.exists(file_path):
        print(f"Error: Input CSV file not found at {file_path}")
        return pd.DataFrame() # Return empty DataFrame if file not found

    try:
        df = pd.read_csv(file_path)
        print(f"Successfully loaded CSV: {os.path.basename(file_path)}")
        return df
    except Exception as e:
        print(f"Error reading CSV file {file_path}: {e}")
        return pd.DataFrame() # Return empty DataFrame on error

# --- Data Processing Function (Optimized - from your provided script) ---
def process_and_aggregate_data(df, chemist_id):
    """
    Filters data for a specific chemist and aggregates total items by year and month.
    Uses efficient pandas operations.
    """
    if df.empty:
        print("Input DataFrame is empty, cannot process.")
        return pd.DataFrame()

    # Ensure required columns exist before proceeding
    required_cols = ['Chemist', 'Year', 'Month', 'Number of Items']
    if not all(col in df.columns for col in required_cols):
        missing = [col for col in required_cols if col not in df.columns]
        print(f"Error: Input DataFrame is missing required columns: {', '.join(missing)}")
        print("Please ensure your merged CSV file contains these columns, or preprocess it to add them.")
        return pd.DataFrame()

    # Convert 'Chemist' to numeric, coercing errors to NaN, then drop NaNs
    df['Chemist'] = pd.to_numeric(df['Chemist'], errors='coerce')
    # Create a copy to avoid SettingWithCopyWarning when modifying
    df_filtered = df.dropna(subset=['Chemist']).copy()

    # Filter by the specific chemist ID
    df_filtered = df_filtered[df_filtered['Chemist'] == chemist_id].copy()

    if df_filtered.empty:
        print(f"No data found for Chemist ID: {chemist_id} after initial filtering.")
        return pd.DataFrame()

    # Ensure 'Year', 'Month', and 'Number of Items' are in appropriate formats
    df_filtered.loc[:, 'Year'] = pd.to_numeric(df_filtered['Year'], errors='coerce').fillna(0).astype(int)
    df_filtered.loc[:, 'Month'] = pd.to_numeric(df_filtered['Month'], errors='coerce').fillna(0).astype(int)
    df_filtered.loc[:, 'Number of Items'] = pd.to_numeric(df_filtered['Number of Items'], errors='coerce').fillna(0)

    # Filter out rows with invalid Year or Month (e.g., 0)
    df_filtered = df_filtered[(df_filtered['Year'] > 0) & (df_filtered['Month'] >= 1) & (df_filtered['Month'] <= 12)].copy()

    if df_filtered.empty:
        print("No valid Year/Month data found after filtering and data type conversion.")
        return pd.DataFrame()

    print(f"Aggregating data for Chemist ID: {chemist_id}")
    # Group by Year and Month and sum 'Number of Items'
    aggregated_df = df_filtered.groupby(['Year', 'Month'])['Number of Items'].sum().reset_index()

    # Rename the aggregated column for clarity
    aggregated_df = aggregated_df.rename(columns={'Number of Items': 'Total Items'})

    # Add the Chemist ID column back
    aggregated_df['Chemist'] = chemist_id

    # Sort by Year and Month for chronological order
    aggregated_df = aggregated_df.sort_values(by=['Year', 'Month']).reset_index(drop=True)

    print("Aggregation complete.")
    # Reorder columns for the final output
    return aggregated_df[['Chemist', 'Year', 'Month', 'Total Items']]

# --- Main Execution ---
if __name__ == "__main__":
    # 1. Load data from the single merged CSV file
    consolidated_data = load_single_csv_file(INPUT_CSV_FILE_PATH)

    # Check if data was loaded successfully
    if not consolidated_data.empty:
        # 2. Process and aggregate data for the specified chemist
        monthly_totals_df = process_and_aggregate_data(consolidated_data, chemist_filter_number)

        # Check if aggregation was successful
        if not monthly_totals_df.empty:
            # 3. Define output file path and save the result
            # Using y_input for part of the filename as in your original script
            new_file_name = f'Chemist{chemist_filter_number}_FilteredData_{y_input.replace(" ", "_")}.xlsx'
            output_file_path = os.path.join(OUTPUT_BASE_FOLDER, new_file_name)

            try:
                monthly_totals_df.to_excel(output_file_path, index=False)
                print(f"Successfully saved aggregated data to: {output_file_path}")
            except Exception as e:
                print(f"Error saving data to Excel file: {e}")
        else:
            print("No data to save after processing and aggregation.")
    else:
        print("No data loaded from the CSV file. Processing cannot continue.")

