import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
# import certifi # No longer strictly needed if verify=False, but doesn't hurt to leave
import warnings # For suppressing InsecureRequestWarning
from urllib3.exceptions import InsecureRequestWarning # For suppressing InsecureRequestWarning

# Suppress only the InsecureRequestWarning caused by verify=False
# This is to keep the output cleaner during diagnostics.
warnings.simplefilter('ignore', InsecureRequestWarning)

# URL of the page to scrape
BASE_URL = "https://bso.hscni.net/directorates/operations/family-practitioner-services/directorates-operations-family-practitioner-services-information-unit/general-pharmaceutical-services-and-prescribing-statistics/dispensing-by-contractor/"

# Directory to save downloaded files
# Using a raw string for the Windows path
DOWNLOAD_DIR = r"C:\Users\Andrew\OneDrive\Documents\2025_PROJECT\2025_PROJECT\html_project\Python_webscrape\Webscrape Data"

# Create the download directory if it doesn't exist
if not os.path.exists(DOWNLOAD_DIR):
    os.makedirs(DOWNLOAD_DIR)
    print(f"Created directory: {DOWNLOAD_DIR}")

def download_file(url, directory):
    """Downloads a file from a given URL into the specified directory."""
    try:
        # Get the filename from the URL
        filename = url.split('/')[-1].split('?')[0] # Basic way to get filename
        filepath = os.path.join(directory, filename)

        # Check if file already exists to avoid re-downloading
        if os.path.exists(filepath):
            print(f"File already exists: {filepath}. Skipping.")
            return True

        print(f"Downloading {filename} from {url}...")
        # WARNING: SSL verification disabled! This is insecure for production.
        response = requests.get(url, stream=True, verify=False) # <-- MODIFIED
        response.raise_for_status()  # Check for request errors

        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"Successfully downloaded: {filepath}")
        return True
    except requests.exceptions.RequestException as e:
        print(f"Error downloading {url}: {e}")
        return False
    except Exception as e:
        print(f"An unexpected error occurred while downloading {url}: {e}")
        return False

def scrape_bso_data(page_url, download_directory):
    """Scrapes the BSO page for Excel file links and downloads them."""
    print(f"Attempting to scrape data from: {page_url}")
    try:
        # WARNING: SSL verification disabled! This is insecure for production.
        response = requests.get(page_url, verify=False) # <-- MODIFIED
        response.raise_for_status() # Check for request errors
    except requests.exceptions.RequestException as e:
        print(f"Error fetching page {page_url}: {e}")
        return

    soup = BeautifulSoup(response.content, 'html.parser')

    files_found_count = 0
    files_downloaded_count = 0

    # Find all <a> tags
    for link_tag in soup.find_all('a', href=True):
        href = link_tag['href']

        # Check if the link points to an .xlsx file and likely within the uploads path
        if href.endswith('.xlsx') and ('wp-content/uploads/' in href or 'bso.hscni.net' in href):
            files_found_count += 1
            # Ensure the URL is absolute
            file_url = urljoin(page_url, href)

            # Try to download the file
            if download_file(file_url, download_directory):
                files_downloaded_count +=1

    if files_found_count == 0:
        print("No .xlsx file links matching the criteria were found on the page.")
    else:
        print(f"\nScraping complete. Found {files_found_count} potential .xlsx files. Successfully downloaded {files_downloaded_count} new files.")

if __name__ == "__main__":
    scrape_bso_data(BASE_URL, DOWNLOAD_DIR)
